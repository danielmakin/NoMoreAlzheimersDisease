{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No More Alzheimer's Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_merge(labelsDir, featuresDir, fieldsToDrop, savePath = None):\n",
    "    '''\n",
    "     Reads all of the files and attempts to merge them based on the VISCODE and RID attributes. \n",
    "     This features some basic data cleaning to allow the classifier to function. \n",
    "     \n",
    "     Args :\n",
    "        labelsDir (String) : Directory path to the label data.\n",
    "        featuresDir (String) : Directory path to feature data.\n",
    "        fieldsToDrop (String[]) : List of fields to drop.\n",
    "     Returns :\n",
    "        SCD, MCI, AD (DataFrame) : Retuns a DataFrame of each class.'''\n",
    "\n",
    "    # Read the two files that are necessary\n",
    "    features = pd.read_csv(featuresDir)\n",
    "    labels = pd.read_csv(labelsDir)\n",
    "\n",
    "    # Now merge these two files and remove any rows that have null values\n",
    "    merged_data = pd.merge(features, labels[['RID', 'VISCODE', 'DX']], on=['RID', 'VISCODE'], how='left').dropna()\n",
    "    # Update Stamp is not relevant for this test\n",
    "    merged_data.drop(fieldsToDrop, axis=1, inplace=True)\n",
    "    # We are not interested in classifying dementia\n",
    "    merged_data = merged_data.replace(\"Dementia\", \"AD\").replace(\"CN\", \"SCD\")\n",
    "\n",
    "    MCI = merged_data.loc[merged_data[\"DX\"] == \"MCI\"]\n",
    "    SCD = merged_data.loc[merged_data[\"DX\"] == \"SCD\"]\n",
    "    AD = merged_data.loc[merged_data[\"DX\"] == \"AD\"]\n",
    "\n",
    "    if savePath != None:\n",
    "        merged_data.to_csv(savePath)\n",
    "\n",
    "    return SCD, MCI, AD\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(df):\n",
    "    '''\n",
    "    Seperate the label from the feature data.\n",
    "    \n",
    "    Args : \n",
    "        df (DataFrame) : The data to be seperated\n",
    "    Returns :\n",
    "        X (DataFrame) : The feature data.\n",
    "        y (list) : The labels associated.'''\n",
    "    \n",
    "    # Independant\n",
    "    X = df.iloc[:, [1, 2]].values\n",
    "    # Dependant\n",
    "    y = df.iloc[:, 3].values\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_data(SCD, MCI, AD, TestingFactor = 0.25):\n",
    "    '''\n",
    "        Now we seperate the training and testing data. Currently using a 25% training test split.\n",
    "\n",
    "        Args : \n",
    "            SCD, MCI, AD (DataFrame) : Data to be split, already split into classes.\n",
    "            TestingFactor (int) [OPTIONAL] : Amount of data put in testing.\n",
    "        Returns :\n",
    "            SCD, MCI, AD, TestData (DataFrame) : Each of the sections of data.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    SCD, TempSCD = train_test_split(SCD, test_size=TestingFactor)\n",
    "    MCI, TempMCI = train_test_split(MCI, test_size=TestingFactor)\n",
    "    AD, TempAD = train_test_split(AD, test_size=TestingFactor)\n",
    "\n",
    "    # concatenate the lists\n",
    "    TempData = [TempSCD, TempMCI, TempAD]\n",
    "    TestData = pd.concat(TempData)\n",
    "\n",
    "    # return required info\n",
    "    return SCD, MCI, AD, TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_svm(df1, df2):\n",
    "    '''\n",
    "        Constructs an SVM with the datasets provided.\n",
    "\n",
    "        Args :\n",
    "            Datasets (DataFrame) : Two DataFrames that the SVM must be made upon.\n",
    "        Returns :\n",
    "            Classifier (SVC) : This is the margin that the data must be acted upon.\n",
    "    '''\n",
    "\n",
    "    # First the two dataframes should be combined\n",
    "    df = [df1, df2]\n",
    "    df = pd.concat(df)\n",
    "    # Get data in the format required\n",
    "    X, y = getXy(df)\n",
    "    # Train the classifier\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "    # Fit to the classifier\n",
    "    classifier = SVC(kernel='rbf', random_state=0)\n",
    "    classifier.fit(X, y)\n",
    "\n",
    "    return classifier, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(classifier, scaler, X):\n",
    "    '''\n",
    "        Test the dataset with each individual SVM\n",
    "\n",
    "        Args :\n",
    "            classifier (SVM) : The Support Vector Machine used for this test\n",
    "            scaler (StandardScaler) : This allows the test data to be scaled to the same proportions as the test data\n",
    "            X (DataFrame) : The feature data WITHOUT labels\n",
    "        Returns :\n",
    "            y_pred (list) : the predicted y-value for each item\n",
    "    '''\n",
    "    # now perform the classification\n",
    "    X = scaler.fit_transform(X)\n",
    "    y_pred = classifier.predict(X)\n",
    "    # return the result of this transcation\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bdt(file_path):\n",
    "    '''\n",
    "        Perform the Binary Decision Tree SVM classification method\n",
    "        \n",
    "        Args :\n",
    "            file_path (String) : Path to the data\n",
    "        Returns :\n",
    "            time (float) : Time taken to perform the test.\n",
    "            accuracy (float) : The accuracy of the model.\n",
    "            confusion_matrix = Confusion matrix for the accuracy.'''\n",
    "    \n",
    "    start = timer()\n",
    "    # read the dataframe and clean\n",
    "    SCD, MCI, AD = read_and_merge('Data/ADNIMERGE_15Jun2023.csv', file_path, ['update_stamp', 'VISCODE'], 'Data/TempFiles/mergeddata.csv')\n",
    "    \n",
    "    # get the test data required, leave training data\n",
    "    SCD, MCI, AD, TestData = split_test_data(SCD, MCI, AD)\n",
    "    \n",
    "\n",
    "    # seperate the labels and the data features\n",
    "    X_test, y_test = getXy(TestData)\n",
    "\n",
    "    # Concatenate MCI\n",
    "    MCIoAD = [MCI, AD]\n",
    "    MCIoAD = pd.concat(MCIoAD)\n",
    "    # Map to the same class\n",
    "    MCIoAD = MCIoAD.replace(\"MCI\", \"MCIoAD\").replace(\"AD\", \"MCIoAD\")\n",
    "\n",
    "    # Test to perform the first step of the DT\n",
    "    SCDMCIAD, scalersma = construct_svm(SCD, MCIoAD)\n",
    "    # SVM for the second level of the BDT\n",
    "    MCIAD, scalarma = construct_svm(MCI, AD)\n",
    "\n",
    "    # Perform the test for the first level of BDT\n",
    "    SCDoMCIAD = test(SCDMCIAD, scalersma, X_test)\n",
    "\n",
    "    # Now run entire set through the MCI, AD classifier. \n",
    "    # However, only the non-SCD items in the previous test will be used\n",
    "    MCIoAD = test(MCIAD, scalarma, X_test)\n",
    "\n",
    "    # Now colalate the results together taking the two classifiers into account\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(SCDoMCIAD)):\n",
    "        if SCDoMCIAD[i] == 'SCD':\n",
    "            results.append('SCD')\n",
    "        else:\n",
    "            # Adds the result of the second level\n",
    "            results.append(MCIoAD[i])\n",
    "\n",
    "    # print(SCDoMCIAD)\n",
    "    print(MCIoAD)\n",
    "\n",
    "    # Print out the time taken and results\n",
    "    end = timer()\n",
    "    print(\"Time Taken : \" + str(end-start))\n",
    "\n",
    "    # construct a confusion matrix\n",
    "    cm = confusion_matrix(y_test, results)\n",
    "    print(cm)\n",
    "    print(\"Accuracy : \" + str(accuracy_score(y_test, results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD' 'MCIoAD'\n",
      " 'MCIoAD' 'MCIoAD' 'MCIoAD']\n",
      "['MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'AD' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'AD'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'AD'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'AD' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'AD'\n",
      " 'AD' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'AD' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI' 'MCI'\n",
      " 'MCI' 'MCI' 'MCI']\n",
      "Time Taken : 0.21809870899960515\n",
      "[[  1 180   0]\n",
      " [  6 224   0]\n",
      " [  0 192   0]]\n",
      "Accuracy : 0.373134328358209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9h/tqk_65w50d95gtyf68q0hv880000gn/T/ipykernel_9940/2633204203.py:15: DtypeWarning: Columns (20,105) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  labels = pd.read_csv(labelsDir)\n"
     ]
    }
   ],
   "source": [
    "bdt(\"Data/Plasma/UPENNPLASMA_27Nov2023.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
